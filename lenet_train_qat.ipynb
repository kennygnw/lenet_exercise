{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lenet_model\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "# _ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())\n",
    "class_names = train_val_dataset.classes\n",
    "\n",
    "# Calculate mean and std of the train dataset\n",
    "imgs = torch.stack([img for img, _ in train_val_dataset], dim=0)\n",
    "mean = imgs.view(1, -1).mean(dim=1)    # or imgs.mean()\n",
    "std = imgs.view(1, -1).std(dim=1)     # or imgs.std()\n",
    "# create Transformation (converting from Image class to Tensor and normalize)\n",
    "mnist_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=mean, std=std)])\n",
    "mnist_trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=False, transform=mnist_transforms)\n",
    "# split to train dataset and validation dataset\n",
    "train_size = int(0.8 * len(mnist_trainset))\n",
    "val_size = len(mnist_trainset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset=mnist_trainset, lengths=[train_size, val_size])\n",
    "\n",
    "# load dataset and set number of data per batch\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "net = lenet_model.LeNet5().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert min-max observers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       "  (c1): Conv2d(\n",
       "    1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (c2): Conv2d(\n",
       "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (c3): Conv2d(\n",
       "    16, 120, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=120, out_features=84, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (fc2): Linear(\n",
       "    in_features=84, out_features=10, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.qconfig = torch.ao.quantization.default_qconfig\n",
    "net.train()\n",
    "net_quantized = torch.ao.quantization.prepare_qat(net) # Insert observers\n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1500/1500 [00:31<00:00, 46.90it/s, loss=0.0548]\n",
      "Epoch 2: 100%|██████████| 1500/1500 [00:34<00:00, 43.95it/s, loss=0.0395]\n",
      "Epoch 3: 100%|██████████| 1500/1500 [00:37<00:00, 40.19it/s, loss=0.032] \n",
      "Epoch 4: 100%|██████████| 1500/1500 [00:32<00:00, 46.14it/s, loss=0.0253]\n",
      "Epoch 5: 100%|██████████| 1500/1500 [00:36<00:00, 41.51it/s, loss=0.0217]\n",
      "Epoch 6: 100%|██████████| 1500/1500 [00:37<00:00, 40.38it/s, loss=0.0179]\n",
      "Epoch 7: 100%|██████████| 1500/1500 [00:36<00:00, 41.23it/s, loss=0.018] \n",
      "Epoch 8: 100%|██████████| 1500/1500 [00:37<00:00, 39.60it/s, loss=0.0134]\n",
      "Epoch 9: 100%|██████████| 1500/1500 [00:31<00:00, 47.34it/s, loss=0.015] \n",
      "Epoch 10: 100%|██████████| 1500/1500 [00:33<00:00, 44.22it/s, loss=0.0108]\n",
      "Epoch 11: 100%|██████████| 1500/1500 [00:32<00:00, 45.71it/s, loss=0.0135]\n",
      "Epoch 12: 100%|██████████| 1500/1500 [00:34<00:00, 43.40it/s, loss=0.00882]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs=12, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x)\n",
    "            # output = net(x.view(-1, 28*28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "            \n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "train(train_dataloader, net_quantized, epochs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, total_iterations: int = None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_dataloader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "            iterations += 1\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the collected statistics during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.42407387495040894, max_val=2.8215432167053223)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       "  (c1): Conv2d(\n",
       "    1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.5149684548377991, max_val=0.3841245174407959)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-8.90822982788086, max_val=7.721226692199707)\n",
       "  )\n",
       "  (c2): Conv2d(\n",
       "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.6840593218803406, max_val=0.4230343997478485)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-27.688060760498047, max_val=14.46810531616211)\n",
       "  )\n",
       "  (c3): Conv2d(\n",
       "    16, 120, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.8825253844261169, max_val=0.5730369687080383)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-43.66505432128906, max_val=31.585952758789062)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=120, out_features=84, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.5300931930541992, max_val=0.4456928074359894)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-37.28495788574219, max_val=33.431461334228516)\n",
       "  )\n",
       "  (fc2): Linear(\n",
       "    in_features=84, out_features=10, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.9050921201705933, max_val=0.25994884967803955)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-88.83059692382812, max_val=45.62309646606445)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Check statistics of the various layers')\n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize the model using the statistics collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_quantized.eval()\n",
    "net_quantized = torch.ao.quantization.convert(net_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       "  (c1): QuantizedConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.13094060122966766, zero_point=68, padding=(2, 2))\n",
       "  (c2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.33193832635879517, zero_point=83)\n",
       "  (c3): QuantizedConv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.5925276279449463, zero_point=74)\n",
       "  (relu): ReLU()\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): QuantizedLinear(in_features=120, out_features=84, scale=0.5568221807479858, zero_point=67, qscheme=torch.per_tensor_affine)\n",
       "  (fc2): QuantizedLinear(in_features=84, out_features=10, scale=1.0586904287338257, zero_point=84, qscheme=torch.per_tensor_affine)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Check statistics of the various layers')\n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights and size of the model after quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after quantization\n",
      "tensor([[[[ 63,  51,  38, -45,   4],\n",
      "          [-30, -46, -67, -70, -36],\n",
      "          [-57, -81, -64,  52,  45],\n",
      "          [  4,   5,  67,  79,  41],\n",
      "          [  9,  56,  38, -42, -67]]],\n",
      "\n",
      "\n",
      "        [[[ 41,   6,   4, -35, -19],\n",
      "          [ 31,  53, -30, -52, -28],\n",
      "          [ 95,  -1, -54, -69,   3],\n",
      "          [ 59, -47, -69, -50,   6],\n",
      "          [ 27, -58, -17,   2,   8]]],\n",
      "\n",
      "\n",
      "        [[[ 19,  21,  64,  29,  24],\n",
      "          [ 11,  82,  37,  44,  74],\n",
      "          [ 42,  -7,   2,  32,  26],\n",
      "          [  8, -95, -65, -92, -35],\n",
      "          [-73, -95, -60, -74, -39]]],\n",
      "\n",
      "\n",
      "        [[[ 34,   2,  25,   2, -49],\n",
      "          [-32,  79,   2,  35,  -4],\n",
      "          [-94, -24,  25, -17, -33],\n",
      "          [-63,  11,  -7,  39,   3],\n",
      "          [ 13,  -7,   5,  50, -47]]],\n",
      "\n",
      "\n",
      "        [[[-16, -29,  13,  20,  27],\n",
      "          [-61, -13,  36, -25,  56],\n",
      "          [-38, -61,  38,  61, -19],\n",
      "          [-66,   0,  16,  58,   9],\n",
      "          [-77,  -1,  32,  34, -23]]],\n",
      "\n",
      "\n",
      "        [[[ -8, -27, -39, -35,  33],\n",
      "          [  9,  -5, -99, -26, -29],\n",
      "          [ 51,  52, -61, -67, -73],\n",
      "          [ -2,  86,  79, -10,  26],\n",
      "          [-28,  12,  68,  16,  29]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print(torch.int_repr(net_quantized.c1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model after quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 375/375 [00:03<00:00, 108.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing the model after quantization')\n",
    "test(net_quantized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "time_start = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "MODEL_NAME = f\"lenet5_mnist_{time_start}.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "torch.save(net_quantized.state_dict(), f=MODEL_PATH / f\"quantized_{MODEL_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
